---
id: "setup/sources/docker"
title: "Collect Docker logs & send them anywhere"
description: "A guide to quickly, and correctly, collect Docker logs and send them anywhere."
keywords: ["docker"]
---

> "I just wanna, like, collect my Docker logs and grep them -- why is all of this so complicated?"
>
> â€” developers

So you want to collect your Docker logs and send them somewhere? Sounds simple!
Sadly, it is not. First, there are many different opinionated ways on how to
"properly" collect your Docker logs. Second, there are many caveats, such as
parsing, enriching, handling split log messages, and more. Fear not! This guide
will get you up and running in minutes, all without becoming a Docker logging
expert.

<!--
     THIS FILE IS AUTOGENERATED!

     To make changes please edit the template located at:

     website/guides/setup/sources/docker.md.erb
-->

## What We'll Accomplish In This Guide

<ol className="list--checks list--lg list--semi-bold list--primary">
  <li>Collect Docker container logs.</li>
  <li>Filter which containers you collect them from.</li>
  <li>Automatically merge logs that Docker splits.</li>
  <li>Enrich your logs with Docker context.</li>
  <li>Send your logs to one or more destinations</li>
  <li className="list--li--arrow list--li--pink">All in just a few minutes. Let's get started!</li>
</ol>

## How It Works

This tutorial works by deploying Vector as a dedicated logging container to collect, transform, and route Docker logs with ease. Vector is a lightweight, high-performance tool for building observability pipelines, and is very well suited for this use case. The diagram below demonstrates how this tutorial works:

import SVG from 'react-inlinesvg';

<SVG src="/img/tutorials/sources/docker.svg" />


## A Step-By-Step Tutorial

<ol className="sections sections--h3">
<li>

### Collect Docker logs

<ol className="sections sections--h4">
<li>

#### Configure Vector

Before we start the Vector container, we need to configure Vector to tell it what to do:

```bash
echo '
[sources.in]
  type = "docker"

[sinks.out]
  inputs = ["in"]
  type = "console"
' > vector.toml
```

import CodeExplanation from '@site/src/components/CodeExplanation';

<CodeExplanation>

* The `vector.toml` file is the Vector configuration file that we'll pass in the next step.
* The [`docker` source][docs.sources.docker] tells Vector to collect Docker logs.
* The the [`console` sink][docs.sinks.console] simply prints the collected logs so that we can manually verify everything is working.

</CodeExplanation>



</li>
<li>

#### Start the Vector container

```bash
docker run \
-v /var/run/docker.sock:/var/run/docker.sock \
-v $PWD/vector.toml:/etc/vector/vector.toml:ro \
timberio/vector:latest-alpine
```

<CodeExplanation>

* The first `-v` flag ensures that Vector has access to the Docker socket. This is how Vector receives Docker logs.
* The second `-v` flag passes the previously created Vector configuration file into the container.

</CodeExplanation>

Hooray! You shoul see output like the following if things are working correctly:

```text
output
```



</li>
</ol>

</li>
<li>

### Send your Docker logs to your destination

Now that Vector is hooked up and receiving our Docker lets, let's send them to one or more destinations.

import Tabs from '@theme/Tabs';

<Tabs
  block={true}
  select={true}
  placeholder={"Select your destination..."}
  values={[{"label":"AWS CloudWatch","value":"aws_cloudwatch"},{"label":"AWS S3","value":"aws_s3"}]}>

import TabItem from '@theme/TabItem';

<TabItem value={"aws_cloudwatch"}>

<ol className="sections sections--h4">
<li>

#### Ensure Vector has write permission to your S3 bucket

In order for Vector to successfully write data to your S3 bucket, you'll need to make sure Vector is using the appropriate AWS IAM credentials that grant it access. If you've been using AWS, you'll likely know how to do this, but if you're new to AWS you'll want to checkout our [AWS authentication guide]().


</li>
<li>

#### Add the `aws_s3` sink to your `vector.toml` file

```bash
echo '
[sinks.aws_s3]
  inputs = ["in"]
  type = "aws_s3"
  bucket = "my-bucket-name"
  compression = "gzip"
  region = "us-east-1"
  key_prefix = "date=%F/"
  batch.max_size = 10490000
  batch.timeout_secs = 300
  encoding.codec = "ndjson"
' >> vector.toml
```

<CodeExplanation>

* The above command _appends_ to your previously created `vector.toml` file.
* The `compression` option gzips the contents to save on storage costs.
* The `key_prefix` option partitions your data by date.
* The `batch.*` options control the file size and age on S3.
* The `encoding.codec` tells Vector how to encode the data before writing it.

</CodeExplanation>

That's it! Let's start Vector:



</li>
</ol>

</TabItem>
<TabItem value={"aws_s3"}>

<ol className="sections sections--h4">
<li>

#### Ensure Vector has write permission to your S3 bucket

In order for Vector to successfully write data to your S3 bucket, you'll need to make sure Vector is using the appropriate AWS IAM credentials that grant it access. If you've been using AWS, you'll likely know how to do this, but if you're new to AWS you'll want to checkout our [AWS authentication guide]().


</li>
<li>

#### Add the `aws_s3` sink to your `vector.toml` file

```bash
echo '
[sinks.aws_s3]
  inputs = ["in"]
  type = "aws_s3"
  bucket = "my-bucket-name"
  compression = "gzip"
  region = "us-east-1"
  key_prefix = "date=%F/"
  batch.max_size = 10490000
  batch.timeout_secs = 300
  encoding.codec = "ndjson"
' >> vector.toml
```

<CodeExplanation>

* The above command _appends_ to your previously created `vector.toml` file.
* The `compression` option gzips the contents to save on storage costs.
* The `key_prefix` option partitions your data by date.
* The `batch.*` options control the file size and age on S3.
* The `encoding.codec` tells Vector how to encode the data before writing it.

</CodeExplanation>

That's it! Let's start Vector:



</li>
</ol>

</TabItem>

</Tabs>

</li>
</ol>

## Next Steps


[docs.sinks.console]: /docs/reference/sinks/console/
[docs.sources.docker]: /docs/reference/sources/docker/
